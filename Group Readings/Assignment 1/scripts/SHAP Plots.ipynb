{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shap\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.special\n",
    "import numpy as np\n",
    "import xgboost as xgb \n",
    "import itertools\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Property 1*: Local Accuracy\n",
    "Local accuracy ensures that the feature attributions must add up to the difference between a given prediction and the average prediction for the background distribution. This property tends to distribute feature attributions across several features when it is not possible to identify a single most informative feature. Hence, local accuracy ensures that the **output of the function** is the **sum of the feature attributions** and requires the model to match output of $f$ for the simplified input $x'$.\n",
    "\n",
    "Local accuracy happens when $x = h(x')$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Features = [ 1.62434536 -0.61175641 -0.52817175 -1.07296862  0.86540763]\n",
      "SHAP values = [ 0.89146267 -0.43752168 -0.31836259 -0.58464256  0.3666341 ]\n",
      "Bias value  = 9.99999999999997\n",
      "       G(x) = 9.9175699377\n",
      "       F(x) = 9.9175699377\n"
     ]
    }
   ],
   "source": [
    "def powerset(iterable):\n",
    "    s = list(iterable)\n",
    "    return itertools.chain.from_iterable(itertools.combinations(s, r) for r in range(len(s)+1))\n",
    "\n",
    "def shapley_kernel(M,s):\n",
    "    if s == 0 or s == M:\n",
    "        return 10000\n",
    "    return (M-1)/(scipy.special.binom(M,s)*s*(M-s))\n",
    "\n",
    "def f(X):\n",
    "    np.random.seed(0)\n",
    "    beta = np.random.rand(X.shape[-1])\n",
    "    return np.dot(X, beta) + 10\n",
    "\n",
    "def kernel_shap(f, x, reference, M):\n",
    "    X = np.zeros((2**M, M + 1))\n",
    "    X[:,-1] = 1\n",
    "    weights = np.zeros(2**M)\n",
    "\n",
    "    # Value function that depends on a specific data instance X\n",
    "    # to explain how each feature contributes to the output of the \n",
    "    # function on this instance\n",
    "    V = np.zeros((2**M, M))\n",
    "    for i in range(2**M):\n",
    "        V[i,:] = reference\n",
    "    \n",
    "    ws = {}\n",
    "    for i,s in enumerate(powerset(range(M))):\n",
    "        s = list(s)\n",
    "        V[i,s] = x[s]\n",
    "        X[i,s] = 1\n",
    "        ws[len(s)] = ws.get(len(s), 0) + shapley_kernel(M,len(s))\n",
    "        weights[i] = shapley_kernel(M,len(s))\n",
    "\n",
    "    # Explanation Model  where V is the simplified inputs\n",
    "    y = f(V)\n",
    "    tmp = np.linalg.inv(np.dot(np.dot(X.T, np.diag(weights)), X))\n",
    "    return np.dot(tmp,  np.dot(np.dot(X.T, np.diag(weights)), y))\n",
    "\n",
    "M = 5\n",
    "np.random.seed(1)\n",
    "x = np.random.randn(M)\n",
    "reference = np.zeros(M)\n",
    "phi = kernel_shap(f, x, reference, M)\n",
    "base_value  = phi[ -1]\n",
    "shap_values = phi[:-1]\n",
    "\n",
    "print(\"   Features =\", x)\n",
    "print(\"SHAP values =\", shap_values)\n",
    "print(\"Bias value  =\", base_value)\n",
    "print(\"       G(x) =\", np.round(np.sum(phi), 10))\n",
    "print(\"       F(x) =\", np.round(f(x), 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sum of all the contributions should be equal [or approximately equal] to the prediction. In other words, the SHAP’s local accuracy property that ensures that the contributions of the features should add up to the difference between the prediction and the average prediction of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP values = [ 0.89146267 -0.43752168 -0.31836259 -0.58464256  0.3666341 ]\n",
      "Bias value  = 10.0\n"
     ]
    }
   ],
   "source": [
    "explainer = shap.KernelExplainer(f, np.reshape(reference, (1, len(reference))))\n",
    "shap_values = explainer.shap_values(x)\n",
    "print(\"SHAP values =\", shap_values)\n",
    "print(\"Bias value  =\", explainer.expected_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Property 3*: Consistency\n",
    "\n",
    "The consistency property states that if a model changes in such a way that the marginal contribution of a feature value increases the same [or stays the same], regardless of other features, the Shapley Value also increases [or stays the same]. \n",
    "\n",
    "Consistency indicates that if a model changes such that some features’ contribution increases or stays the same regardless of the other inputs, that input's attribution should not decrease.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 120 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n",
      "Using 120 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n",
      "100%|██████████| 30/30 [00:02<00:00, 11.52it/s]\n",
      "100%|██████████| 30/30 [00:02<00:00, 12.11it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(*shap.datasets.iris(), test_size = 0.2, random_state = 0)\n",
    "\n",
    "svm = sklearn.svm.SVC(kernel = 'rbf', probability = True)\n",
    "svm.fit(X_train, Y_train)\n",
    "svm_predictions = svm.predict_proba(X_test)\n",
    "\n",
    "knn = KNeighborsClassifier(3)\n",
    "knn.fit(X_train, Y_train)\n",
    "knn_predictions = knn.predict_proba(X_test)\n",
    "\n",
    "explainer_svm = shap.KernelExplainer(model = svm.predict_proba, data = X_train)\n",
    "explainer_knn = shap.KernelExplainer(model = knn.predict_proba, data = X_train)\n",
    "\n",
    "shap_values_svm = explainer_svm.shap_values(X = X_test)\n",
    "shap_values_knn = explainer_knn.shap_values(X = X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:02<00:00, 13.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Model Prediction: \t1.1267809867858887\n",
      "Explanatory Model Prediction: \t4.430342075145531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X,y = sklearn.datasets.load_iris(return_X_y = True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "model = xgb.XGBRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "explainer = shap.KernelExplainer(model.predict, X_train[:100], link = 'identity')\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "print(f'Original Model Prediction: \\t{model.predict(X_test)[0]}')\n",
    "print(f'Explanatory Model Prediction: \\t{(explainer.fnull + np.sum(shap_values))[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHAP Waterfall Plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3608206ce1eb198bd23abae205dd191f991de1c92dbe872a18ef9e948d8a869d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
